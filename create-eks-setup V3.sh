#!/bin/bash

# ============================================================================
# ğŸš€ EKS DEPLOYMENT SCRIPT MODULAR - AMAZON ELASTIC KUBERNETES SERVICE
# ============================================================================
# Autor: Criado com Amazon Q
# VersÃ£o: 3.0 - Modular, Seguro e VerificÃ¡vel
# DescriÃ§Ã£o: Script modular para criar cluster EKS passo a passo
# 
# CARACTERÃSTICAS:
# âœ… ExecuÃ§Ã£o passo a passo
# âœ… VerificaÃ§Ã£o de cada etapa
# âœ… Seguro para qualquer conta AWS
# âœ… NÃ£o deleta recursos existentes
# âœ… Permite execuÃ§Ã£o individual de passos
# 
# USO:
# ./eks-setup.sh --all              # Executar todos os passos
# ./eks-setup.sh --step 1           # Executar passo especÃ­fico
# ./eks-setup.sh --verify           # Verificar deployment
# ./eks-setup.sh --check            # Verificar prÃ©-requisitos
# ============================================================================

# ============================================================================
# ğŸš€ COMO USAR
# ============================================================================
# 1. Salvar o script
#nano eks-setup.sh
# (colar o cÃ³digo acima)

# 2. Dar permissÃ£o
#chmod +x eks-setup.sh

# 3. Verificar prÃ©-requisitos
#./eks-setup.sh --check

# 4. Executar tudo
#./eks-setup.sh --all

# 5. Ou executar passo a passo
#./eks-setup.sh --step 1  # Rede
#./eks-setup.sh --step 2  # Roles
# ... etc

# 6. Verificar
#./eks-setup.sh --verify

# 7. Gerar relatÃ³rio
#./eks-setup.sh --report







set -e  # Parar em caso de erro

# ConfiguraÃ§Ãµes - MODIFIQUE AQUI SE NECESSÃRIO
PROJECT_NAME="fcg-eks-user"
CLUSTER_NAME="fcg-eks-user-cluster"
NODEGROUP_NAME="fcg-worker-nodes-micro"
AWS_REGION="us-east-1"
INSTANCE_TYPE="t3.micro"  # Confirmado: t3.micro
NODE_MIN_SIZE=1
NODE_MAX_SIZE=2
NODE_DESIRED_SIZE=2

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# FunÃ§Ãµes de log
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

warn() {
    echo -e "${YELLOW}[AVISO] $1${NC}"
}

error() {
    echo -e "${RED}[ERRO] $1${NC}"
    exit 1
}

info() {
    echo -e "${BLUE}[INFO] $1${NC}"
}

success() {
    echo -e "${PURPLE}[SUCESSO] $1${NC}"
}

step_header() {
    echo ""
    echo -e "${CYAN}============================================================================${NC}"
    echo -e "${CYAN}$1${NC}"
    echo -e "${CYAN}============================================================================${NC}"
    echo ""
}

# ============================================================================
# FUNÃ‡ÃƒO DE VERIFICAÃ‡ÃƒO DE PRÃ‰-REQUISITOS
# ============================================================================

check_prerequisites() {
    step_header "ğŸ” VERIFICANDO PRÃ‰-REQUISITOS"
    
    local all_good=true
    
    # 1. Verificar AWS CLI
    if command -v aws &> /dev/null; then
        success "âœ… AWS CLI encontrado: $(aws --version | head -n1)"
    else
        error "âŒ AWS CLI nÃ£o encontrado. Instale: https://aws.amazon.com/cli/"
        all_good=false
    fi
    
    # 2. Verificar kubectl
    if command -v kubectl &> /dev/null; then
        success "âœ… kubectl encontrado: $(kubectl version --client --short 2>/dev/null || echo 'versÃ£o nÃ£o detectada')"
    else
        error "âŒ kubectl nÃ£o encontrado. Instale: https://kubernetes.io/docs/tasks/tools/"
        all_good=false
    fi
    
    # 3. Verificar jq
    if command -v jq &> /dev/null; then
        success "âœ… jq encontrado: $(jq --version)"
    else
        warn "âš ï¸  jq nÃ£o encontrado. Tentando instalar..."
        if command -v apt-get &> /dev/null; then
            sudo apt-get update && sudo apt-get install -y jq
        elif command -v yum &> /dev/null; then
            sudo yum install -y jq
        elif command -v brew &> /dev/null; then
            brew install jq
        else
            error "âŒ Instale jq manualmente: https://stedolan.github.io/jq/"
            all_good=false
        fi
    fi
    
    # 4. Verificar credenciais AWS
    if aws sts get-caller-identity &> /dev/null; then
        local account_id=$(aws sts get-caller-identity --query Account --output text)
        local user_arn=$(aws sts get-caller-identity --query Arn --output text)
        success "âœ… Credenciais AWS vÃ¡lidas"
        info "   Conta: $account_id"
        info "   UsuÃ¡rio: $user_arn"
        info "   RegiÃ£o: $AWS_REGION"
    else
        error "âŒ Credenciais AWS nÃ£o configuradas. Execute: aws configure"
        all_good=false
    fi
    
    # 5. Verificar permissÃµes bÃ¡sicas
    info "Verificando permissÃµes AWS bÃ¡sicas..."
    
    # Testar EC2
    if aws ec2 describe-regions --region $AWS_REGION &>/dev/null; then
        success "âœ… PermissÃµes EC2 OK"
    else
        error "âŒ Sem permissÃµes EC2"
        all_good=false
    fi
    
    # Testar IAM
    if aws iam get-account-summary &>/dev/null; then
        success "âœ… PermissÃµes IAM OK"
    else
        error "âŒ Sem permissÃµes IAM"
        all_good=false
    fi
    
    # Testar EKS
    if aws eks list-clusters --region $AWS_REGION &>/dev/null; then
        success "âœ… PermissÃµes EKS OK"
    else
        error "âŒ Sem permissÃµes EKS"
        all_good=false
    fi
    
    if [ "$all_good" = true ]; then
        success "ğŸ‰ Todos os prÃ©-requisitos atendidos!"
        return 0
    else
        error "âŒ Alguns prÃ©-requisitos nÃ£o foram atendidos. Corrija antes de continuar."
        return 1
    fi
}

# ============================================================================
# FUNÃ‡ÃƒO PARA VERIFICAR SE RECURSO JÃ EXISTE
# ============================================================================

resource_exists() {
    local resource_type=$1
    local resource_name=$2
    
    case $resource_type in
        "vpc")
            aws ec2 describe-vpcs --filters "Name=tag:Name,Values=$resource_name" --query 'Vpcs[0].VpcId' --output text 2>/dev/null | grep -v "None" &>/dev/null
            ;;
        "cluster")
            aws eks describe-cluster --name $resource_name --region $AWS_REGION &>/dev/null
            ;;
        "nodegroup")
            aws eks describe-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name $resource_name --region $AWS_REGION &>/dev/null
            ;;
        "iam-role")
            aws iam get-role --role-name $resource_name &>/dev/null
            ;;
        "iam-user")
            aws iam get-user --user-name $resource_name &>/dev/null
            ;;
        "iam-policy")
            aws iam get-policy --policy-arn $resource_name &>/dev/null
            ;;
        *)
            return 1
            ;;
    esac
}

# ============================================================================
# PASSO 1: CRIAR INFRAESTRUTURA DE REDE
# ============================================================================

step1_create_network() {
    step_header "ğŸ“¡ PASSO 1/7: CRIANDO INFRAESTRUTURA DE REDE"
    
    # Verificar se VPC jÃ¡ existe
    if resource_exists "vpc" "${PROJECT_NAME}-vpc"; then
        warn "VPC ${PROJECT_NAME}-vpc jÃ¡ existe. Pulando criaÃ§Ã£o da rede."
        info "Para usar VPC existente, certifique-se que tem as configuraÃ§Ãµes corretas."
        return 0
    fi
    
    # 1.1 Criar VPC
    info "Criando VPC..."
    local vpc_id=$(aws ec2 create-vpc \
      --cidr-block 10.0.0.0/16 \
      --query 'Vpc.VpcId' \
      --output text)

    aws ec2 create-tags \
      --resources $vpc_id \
      --tags Key=Name,Value=${PROJECT_NAME}-vpc Key=Project,Value=$PROJECT_NAME

    success "âœ… VPC criada: $vpc_id"

    # 1.2 Criar Internet Gateway
    info "Criando Internet Gateway..."
    local igw_id=$(aws ec2 create-internet-gateway \
      --query 'InternetGateway.InternetGatewayId' \
      --output text)

    aws ec2 attach-internet-gateway \
      --vpc-id $vpc_id \
      --internet-gateway-id $igw_id

    aws ec2 create-tags \
      --resources $igw_id \
      --tags Key=Name,Value=${PROJECT_NAME}-igw Key=Project,Value=$PROJECT_NAME

    success "âœ… Internet Gateway criado: $igw_id"

    # 1.3 Criar Subnets
    info "Criando Subnets..."
    local subnet1_id=$(aws ec2 create-subnet \
      --vpc-id $vpc_id \
      --cidr-block 10.0.1.0/24 \
      --availability-zone ${AWS_REGION}a \
      --query 'Subnet.SubnetId' \
      --output text)

    local subnet2_id=$(aws ec2 create-subnet \
      --vpc-id $vpc_id \
      --cidr-block 10.0.2.0/24 \
      --availability-zone ${AWS_REGION}b \
      --query 'Subnet.SubnetId' \
      --output text)

    aws ec2 create-tags \
      --resources $subnet1_id \
      --tags Key=Name,Value=${PROJECT_NAME}-subnet-1 Key=Project,Value=$PROJECT_NAME

    aws ec2 create-tags \
      --resources $subnet2_id \
      --tags Key=Name,Value=${PROJECT_NAME}-subnet-2 Key=Project,Value=$PROJECT_NAME

    success "âœ… Subnets criadas: $subnet1_id, $subnet2_id"

    # 1.4 Configurar Route Table
    info "Configurando Route Table..."
    local route_table_id=$(aws ec2 create-route-table \
      --vpc-id $vpc_id \
      --query 'RouteTable.RouteTableId' \
      --output text)

    aws ec2 create-route \
      --route-table-id $route_table_id \
      --destination-cidr-block 0.0.0.0/0 \
      --gateway-id $igw_id

    aws ec2 associate-route-table \
      --subnet-id $subnet1_id \
      --route-table-id $route_table_id

    aws ec2 associate-route-table \
      --subnet-id $subnet2_id \
      --route-table-id $route_table_id

    aws ec2 create-tags \
      --resources $route_table_id \
      --tags Key=Name,Value=${PROJECT_NAME}-rt Key=Project,Value=$PROJECT_NAME

    # 1.5 Habilitar auto-assign IP pÃºblico
    aws ec2 modify-subnet-attribute \
      --subnet-id $subnet1_id \
      --map-public-ip-on-launch

    aws ec2 modify-subnet-attribute \
      --subnet-id $subnet2_id \
      --map-public-ip-on-launch

    success "âœ… Roteamento configurado"

    # 1.6 Criar Security Group
    info "Criando Security Group..."
    local sg_id=$(aws ec2 create-security-group \
      --group-name ${PROJECT_NAME}-sg \
      --description "Security group for EKS cluster" \
      --vpc-id $vpc_id \
      --query 'GroupId' \
      --output text)

    # Adicionar regras bÃ¡sicas
    aws ec2 authorize-security-group-ingress \
      --group-id $sg_id \
      --protocol tcp \
      --port 443 \
      --cidr 0.0.0.0/0

    aws ec2 authorize-security-group-ingress \
      --group-id $sg_id \
      --protocol tcp \
      --port 80 \
      --cidr 0.0.0.0/0

    aws ec2 create-tags \
      --resources $sg_id \
      --tags Key=Name,Value=${PROJECT_NAME}-sg Key=Project,Value=$PROJECT_NAME

    success "âœ… Security Group criado: $sg_id"

    # Salvar IDs para prÃ³ximos passos
    cat > .eks-network-info << EOF
VPC_ID=$vpc_id
IGW_ID=$igw_id
SUBNET1_ID=$subnet1_id
SUBNET2_ID=$subnet2_id
ROUTE_TABLE_ID=$route_table_id
SG_ID=$sg_id
EOF

    success "ğŸ‰ PASSO 1 CONCLUÃDO: Infraestrutura de rede criada!"
}

# ============================================================================
# PASSO 2: CRIAR IAM ROLES PARA EKS
# ============================================================================

step2_create_eks_roles() {
    step_header "ğŸ‘¤ PASSO 2/7: CRIANDO IAM ROLES PARA EKS"
    
    # 2.1 Verificar e criar EKS Cluster Role
    if resource_exists "iam-role" "${PROJECT_NAME}-cluster-role"; then
        warn "Role ${PROJECT_NAME}-cluster-role jÃ¡ existe. Pulando criaÃ§Ã£o."
    else
        info "Criando EKS Cluster Service Role..."
        aws iam create-role \
          --role-name ${PROJECT_NAME}-cluster-role \
          --assume-role-policy-document '{
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": {
                  "Service": "eks.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
              }
            ]
          }' \
          --tags Key=Project,Value=$PROJECT_NAME > /dev/null

        aws iam attach-role-policy \
          --role-name ${PROJECT_NAME}-cluster-role \
          --policy-arn arn:aws:iam::aws:policy/AmazonEKSClusterPolicy

        success "âœ… EKS Cluster Role criado"
    fi

    # 2.2 Verificar e criar EKS Node Group Role
    if resource_exists "iam-role" "${PROJECT_NAME}-node-role"; then
        warn "Role ${PROJECT_NAME}-node-role jÃ¡ existe. Pulando criaÃ§Ã£o."
    else
        info "Criando EKS Node Group Role..."
        aws iam create-role \
          --role-name ${PROJECT_NAME}-node-role \
          --assume-role-policy-document '{
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": {
                  "Service": "ec2.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
              }
            ]
          }' \
          --tags Key=Project,Value=$PROJECT_NAME > /dev/null

        # Anexar polÃ­ticas obrigatÃ³rias
        aws iam attach-role-policy \
          --role-name ${PROJECT_NAME}-node-role \
          --policy-arn arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy

        aws iam attach-role-policy \
          --role-name ${PROJECT_NAME}-node-role \
          --policy-arn arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy

        aws iam attach-role-policy \
          --role-name ${PROJECT_NAME}-node-role \
          --policy-arn arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly

        success "âœ… EKS Node Group Role criado"
    fi

    success "ğŸ‰ PASSO 2 CONCLUÃDO: IAM Roles para EKS criados!"
}

# ============================================================================
# PASSO 3: CRIAR USUÃRIO ADMIN
# ============================================================================

step3_create_admin_user() {
    step_header "ğŸ”§ PASSO 3/7: CRIANDO USUÃRIO ADMIN"
    
    local account_id=$(aws sts get-caller-identity --query Account --output text)
    
    # 3.1 Verificar e criar usuÃ¡rio admin
    if resource_exists "iam-user" "${PROJECT_NAME}-admin"; then
        warn "UsuÃ¡rio ${PROJECT_NAME}-admin jÃ¡ existe. Pulando criaÃ§Ã£o."
    else
        info "Criando usuÃ¡rio Admin..."
        aws iam create-user \
          --user-name ${PROJECT_NAME}-admin \
          --tags Key=Project,Value=$PROJECT_NAME > /dev/null

        success "âœ… UsuÃ¡rio admin criado: ${PROJECT_NAME}-admin"
    fi

    # 3.2 Verificar e criar polÃ­tica admin
    local admin_policy_arn="arn:aws:iam::${account_id}:policy/${PROJECT_NAME}-AdminPolicy"
    if resource_exists "iam-policy" "$admin_policy_arn"; then
        warn "PolÃ­tica ${PROJECT_NAME}-AdminPolicy jÃ¡ existe. Pulando criaÃ§Ã£o."
    else
        info "Criando polÃ­tica admin..."
        aws iam create-policy \
          --policy-name ${PROJECT_NAME}-AdminPolicy \
          --policy-document '{
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Action": [
                  "eks:*",
                  "ec2:DescribeInstances",
                  "ec2:DescribeSecurityGroups",
                  "ec2:DescribeSubnets",
                  "ec2:DescribeVpcs",
                  "iam:GetRole",
                  "iam:ListRoles"
                ],
                "Resource": "*"
              }
            ]
          }' \
          --tags Key=Project,Value=$PROJECT_NAME > /dev/null

        success "âœ… PolÃ­tica admin criada"
    fi

    # 3.3 Anexar polÃ­tica ao usuÃ¡rio
    info "Anexando polÃ­tica ao usuÃ¡rio admin..."
    aws iam attach-user-policy \
      --user-name ${PROJECT_NAME}-admin \
      --policy-arn $admin_policy_arn 2>/dev/null || warn "PolÃ­tica jÃ¡ pode estar anexada"

    success "ğŸ‰ PASSO 3 CONCLUÃDO: UsuÃ¡rio admin configurado!"
}

# ============================================================================
# PASSO 4: CRIAR USUÃRIO GITHUB CI/CD
# ============================================================================

step4_create_github_user() {
    step_header "ğŸ¤– PASSO 4/7: CRIANDO USUÃRIO GITHUB CI/CD"
    
    local account_id=$(aws sts get-caller-identity --query Account --output text)
    
    # 4.1 Verificar e criar usuÃ¡rio GitHub
    if resource_exists "iam-user" "${PROJECT_NAME}-github-cicd"; then
        warn "UsuÃ¡rio ${PROJECT_NAME}-github-cicd jÃ¡ existe. Pulando criaÃ§Ã£o."
    else
        info "Criando usuÃ¡rio GitHub CI/CD..."
        aws iam create-user \
          --user-name ${PROJECT_NAME}-github-cicd \
          --tags Key=Project,Value=$PROJECT_NAME > /dev/null

        success "âœ… UsuÃ¡rio GitHub CI/CD criado: ${PROJECT_NAME}-github-cicd"
    fi

    # 4.2 Verificar e criar polÃ­tica GitHub CI/CD
    local github_policy_arn="arn:aws:iam::${account_id}:policy/${PROJECT_NAME}-GitHubCICDPolicy"
    if resource_exists "iam-policy" "$github_policy_arn"; then
        warn "PolÃ­tica ${PROJECT_NAME}-GitHubCICDPolicy jÃ¡ existe. Pulando criaÃ§Ã£o."
    else
        info "Criando polÃ­tica completa para GitHub CI/CD..."
        aws iam create-policy \
          --policy-name ${PROJECT_NAME}-GitHubCICDPolicy \
          --policy-document '{
            "Version": "2012-10-17",
            "Statement": [
              {
                "Sid": "EKSFullAccess",
                "Effect": "Allow",
                "Action": ["eks:*"],
                "Resource": "*"
              },
              {
                "Sid": "ECRFullAccess",
                "Effect": "Allow",
                "Action": ["ecr:*"],
                "Resource": "*"
              },
              {
                "Sid": "EC2ForEKS",
                "Effect": "Allow",
                "Action": [
                  "ec2:Describe*",
                  "ec2:CreateTags",
                  "ec2:DeleteTags"
                ],
                "Resource": "*"
              },
              {
                "Sid": "IAMForEKS",
                "Effect": "Allow",
                "Action": [
                  "iam:GetRole",
                  "iam:PassRole",
                  "iam:ListAttachedRolePolicies",
                  "iam:GetPolicy",
                  "iam:GetPolicyVersion"
                ],
                "Resource": "*"
              },
              {
                "Sid": "CloudFormationAccess",
                "Effect": "Allow",
                "Action": ["cloudformation:*"],
                "Resource": "*"
              },
              {
                "Sid": "S3ForArtifacts",
                "Effect": "Allow",
                "Action": [
                  "s3:GetObject",
                  "s3:PutObject",
                  "s3:DeleteObject",
                  "s3:ListBucket",
                  "s3:CreateBucket",
                  "s3:GetBucketLocation"
                ],
                "Resource": "*"
              },
              {
                "Sid": "LogsAndMonitoring",
                "Effect": "Allow",
                "Action": ["logs:*", "cloudwatch:*"],
                "Resource": "*"
              },
              {
                "Sid": "LoadBalancerAccess",
                "Effect": "Allow",
                "Action": ["elasticloadbalancing:*"],
                "Resource": "*"
              },
              {
                "Sid": "AutoScalingAccess",
                "Effect": "Allow",
                "Action": ["autoscaling:*", "application-autoscaling:*"],
                "Resource": "*"
              },
              {
                "Sid": "SecretsAccess",
                "Effect": "Allow",
                "Action": [
                  "ssm:GetParameter",
                  "ssm:GetParameters",
                  "ssm:PutParameter",
                  "secretsmanager:GetSecretValue"
                ],
                "Resource": "*"
              }
            ]
          }' \
          --tags Key=Project,Value=$PROJECT_NAME > /dev/null

        success "âœ… PolÃ­tica GitHub CI/CD criada"
    fi

    # 4.3 Anexar polÃ­tica ao usuÃ¡rio
    info "Anexando polÃ­tica ao usuÃ¡rio GitHub..."
    aws iam attach-user-policy \
      --user-name ${PROJECT_NAME}-github-cicd \
      --policy-arn $github_policy_arn 2>/dev/null || warn "PolÃ­tica jÃ¡ pode estar anexada"

    # 4.4 Criar access keys (apenas se nÃ£o existirem)
    local existing_keys=$(aws iam list-access-keys --user-name ${PROJECT_NAME}-github-cicd --query 'AccessKeyMetadata' --output text 2>/dev/null || echo "")
    
    if [ -z "$existing_keys" ] || [ "$existing_keys" = "None" ]; then
        info "Criando access keys para GitHub Actions..."
        local github_keys=$(aws iam create-access-key --user-name ${PROJECT_NAME}-github-cicd --output json)
        local github_access_key=$(echo $github_keys | jq -r '.AccessKey.AccessKeyId')
        local github_secret_key=$(echo $github_keys | jq -r '.AccessKey.SecretAccessKey')

        # Salvar credenciais
        cat > .eks-github-credentials << EOF
GITHUB_ACCESS_KEY=$github_access_key
GITHUB_SECRET_KEY=$github_secret_key
EOF

        success "âœ… Access keys criadas e salvas"
    else
        warn "Access keys jÃ¡ existem para o usuÃ¡rio GitHub CI/CD"
        info "Se precisar de novas keys, delete as existentes primeiro"
    fi

    success "ğŸ‰ PASSO 4 CONCLUÃDO: UsuÃ¡rio GitHub CI/CD configurado!"
}

# ============================================================================
# PASSO 5: AGUARDAR PROPAGAÃ‡ÃƒO
# ============================================================================

step5_wait_propagation() {
    step_header "â³ PASSO 5/7: AGUARDANDO PROPAGAÃ‡ÃƒO DOS ROLES"
    
    info "Aguardando 30 segundos para propagaÃ§Ã£o dos IAM roles..."
    
    for i in {30..1}; do
        echo -ne "\râ³ Aguardando: $i segundos restantes..."
        sleep 1
    done
    echo ""
    
    success "ğŸ‰ PASSO 5 CONCLUÃDO: PropagaÃ§Ã£o finalizada!"
}

# ============================================================================
# PASSO 6: CRIAR CLUSTER EKS
# ============================================================================

step6_create_eks_cluster() {
    step_header "ğŸ¯ PASSO 6/7: CRIANDO CLUSTER EKS"
    
    # Verificar se cluster jÃ¡ existe
    if resource_exists "cluster" "$CLUSTER_NAME"; then
        warn "Cluster $CLUSTER_NAME jÃ¡ existe. Pulando criaÃ§Ã£o."
        return 0
    fi

    # Carregar informaÃ§Ãµes da rede
    if [ ! -f .eks-network-info ]; then
        error "Arquivo .eks-network-info nÃ£o encontrado. Execute o Passo 1 primeiro."
        return 1
    fi
    
    source .eks-network-info
    local account_id=$(aws sts get-caller-identity --query Account --output text)

    # 6.1 Criar EKS Cluster
    info "Criando EKS Cluster (pode levar 10-15 minutos)..."
    aws eks create-cluster \
      --name $CLUSTER_NAME \
      --version 1.30 \
      --role-arn arn:aws:iam::${account_id}:role/${PROJECT_NAME}-cluster-role \
      --resources-vpc-config subnetIds=${SUBNET1_ID},${SUBNET2_ID},securityGroupIds=${SG_ID} \
      --tags Project=$PROJECT_NAME > /dev/null

    success "âœ… Comando de criaÃ§Ã£o do cluster enviado"

    # 6.2 Aguardar cluster ficar ativo
    info "â³ Aguardando cluster ficar ativo..."
    info "ğŸ“Š Isso pode levar 10-15 minutos, seja paciente..."
    
    local start_time=$(date +%s)
    while true; do
        local status=$(aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.status' --output text 2>/dev/null || echo "NOT_FOUND")
        local current_time=$(date +%s)
        local elapsed=$((current_time - start_time))
        
        if [ "$status" = "ACTIVE" ]; then
            echo ""
            success "âœ… Cluster EKS ativo!"
            break
        elif [ "$status" = "FAILED" ]; then
            echo ""
            error "âŒ Falha na criaÃ§Ã£o do cluster"
            return 1
        elif [ $elapsed -gt 1200 ]; then  # 20 minutos timeout
            echo ""
            error "âŒ Timeout na criaÃ§Ã£o do cluster (20 minutos)"
            return 1
        else
            echo -ne "\râ³ Status: $status | Tempo: ${elapsed}s | $(date +'%H:%M:%S')"
            sleep 30
        fi
    done

    success "ğŸ‰ PASSO 6 CONCLUÃDO: Cluster EKS criado e ativo!"
}

# ============================================================================
# PASSO 7: CRIAR NODE GROUP
# ============================================================================

step7_create_node_group() {
    step_header "ğŸ–¥ï¸ PASSO 7/7: CRIANDO NODE GROUP"
    
    # Verificar se node group jÃ¡ existe
    if resource_exists "nodegroup" "$NODEGROUP_NAME"; then
        warn "Node Group $NODEGROUP_NAME jÃ¡ existe. Pulando criaÃ§Ã£o."
        return 0
    fi

    # Carregar informaÃ§Ãµes da rede
    if [ ! -f .eks-network-info ]; then
        error "Arquivo .eks-network-info nÃ£o encontrado. Execute o Passo 1 primeiro."
        return 1
    fi
    
    source .eks-network-info
    local account_id=$(aws sts get-caller-identity --query Account --output text)

    # 7.1 Criar Node Group
    info "Criando Node Group com instÃ¢ncias $INSTANCE_TYPE..."
    aws eks create-nodegroup \
      --cluster-name $CLUSTER_NAME \
      --nodegroup-name $NODEGROUP_NAME \
      --instance-types $INSTANCE_TYPE \
      --node-role arn:aws:iam::${account_id}:role/${PROJECT_NAME}-node-role \
      --subnets $SUBNET1_ID $SUBNET2_ID \
      --scaling-config minSize=$NODE_MIN_SIZE,maxSize=$NODE_MAX_SIZE,desiredSize=$NODE_DESIRED_SIZE \
      --tags Project=$PROJECT_NAME > /dev/null

    success "âœ… Comando de criaÃ§Ã£o do node group enviado"

    # 7.2 Aguardar node group ficar ativo
    info "â³ Aguardando node group ficar ativo..."
    
    local start_time=$(date +%s)
    while true; do
        local status=$(aws eks describe-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP_NAME --query 'nodegroup.status' --output text 2>/dev/null || echo "NOT_FOUND")
        local current_time=$(date +%s)
        local elapsed=$((current_time - start_time))
        
        if [ "$status" = "ACTIVE" ]; then
            echo ""
            success "âœ… Node Group ativo!"
            break
        elif [ "$status" = "CREATE_FAILED" ] || [ "$status" = "FAILED" ]; then
            echo ""
            error "âŒ Falha na criaÃ§Ã£o do node group"
            return 1
        elif [ $elapsed -gt 900 ]; then  # 15 minutos timeout
            echo ""
            error "âŒ Timeout na criaÃ§Ã£o do node group (15 minutos)"
            return 1
        else
            echo -ne "\râ³ Status: $status | Tempo: ${elapsed}s | $(date +'%H:%M:%S')"
            sleep 30
        fi
    done

    # 7.3 Configurar kubectl
    info "Configurando kubectl..."
    aws eks update-kubeconfig --region $AWS_REGION --name $CLUSTER_NAME

    success "âœ… kubectl configurado"

    # 7.4 Configurar RBAC
    info "Configurando RBAC para usuÃ¡rio admin..."
    kubectl create clusterrolebinding ${PROJECT_NAME}-admin-binding \
      --clusterrole=cluster-admin \
      --user=${PROJECT_NAME}-admin 2>/dev/null || warn "RBAC binding jÃ¡ pode existir"

    success "âœ… RBAC configurado"

    # 7.5 Verificar nodes
    info "Verificando nodes do cluster..."
    kubectl get nodes

    success "ğŸ‰ PASSO 7 CONCLUÃDO: Node Group criado e configurado!"
}

# ============================================================================
# FUNÃ‡ÃƒO DE VERIFICAÃ‡ÃƒO COMPLETA
# ============================================================================

verify_deployment() {
    step_header "ğŸ” VERIFICAÃ‡ÃƒO COMPLETA DO DEPLOYMENT"
    
    local all_good=true
    
    # 1. Verificar cluster
    info "1. Verificando Cluster EKS..."
    local cluster_status=$(aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.status' --output text 2>/dev/null || echo "NOT_FOUND")
    
    if [ "$cluster_status" = "ACTIVE" ]; then
        success "âœ… Cluster EKS estÃ¡ ATIVO"
        local cluster_version=$(aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.version' --output text)
        info "   Nome: $CLUSTER_NAME"
        info "   VersÃ£o: $cluster_version"
        info "   Status: $cluster_status"
    else
        error "âŒ Cluster EKS nÃ£o estÃ¡ ativo: $cluster_status"
        all_good=false
    fi

    # 2. Verificar node group
    info "2. Verificando Node Group..."
    local nodegroup_status=$(aws eks describe-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP_NAME --query 'nodegroup.status' --output text 2>/dev/null || echo "NOT_FOUND")
    
    if [ "$nodegroup_status" = "ACTIVE" ]; then
        success "âœ… Node Group estÃ¡ ATIVO"
        local instance_types=$(aws eks describe-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP_NAME --query 'nodegroup.instanceTypes[0]' --output text)
        local desired_size=$(aws eks describe-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP_NAME --query 'nodegroup.scalingConfig.desiredSize' --output text)
        info "   Nome: $NODEGROUP_NAME"
        info "   Tipo de instÃ¢ncia: $instance_types"
        info "   Tamanho desejado: $desired_size"
        info "   Status: $nodegroup_status"
    else
        error "âŒ Node Group nÃ£o estÃ¡ ativo: $nodegroup_status"
        all_good=false
    fi

    # 3. Verificar kubectl
    info "3. Verificando kubectl..."
    if command -v kubectl &> /dev/null; then
        success "âœ… kubectl estÃ¡ instalado"
        if kubectl cluster-info &> /dev/null; then
            success "âœ… kubectl estÃ¡ configurado corretamente"
            echo ""
            info "Nodes do cluster:"
            kubectl get nodes
            echo ""
            info "Pods do sistema:"
            kubectl get pods -A | head -10
        else
            warn "âš ï¸  kubectl nÃ£o estÃ¡ configurado. Execute:"
            info "   aws eks update-kubeconfig --region $AWS_REGION --name $CLUSTER_NAME"
        fi
    else
        error "âŒ kubectl nÃ£o estÃ¡ instalado"
        all_good=false
    fi

    # 4. Verificar usuÃ¡rios IAM
    info "4. Verificando usuÃ¡rios IAM..."
    if resource_exists "iam-user" "${PROJECT_NAME}-admin"; then
        success "âœ… UsuÃ¡rio admin existe: ${PROJECT_NAME}-admin"
    else
        error "âŒ UsuÃ¡rio admin nÃ£o encontrado"
        all_good=false
    fi

    if resource_exists "iam-user" "${PROJECT_NAME}-github-cicd"; then
        success "âœ… UsuÃ¡rio GitHub CI/CD existe: ${PROJECT_NAME}-github-cicd"
    else
        error "âŒ UsuÃ¡rio GitHub CI/CD nÃ£o encontrado"
        all_good=false
    fi

    # 5. Verificar roles IAM
    info "5. Verificando roles IAM..."
    if resource_exists "iam-role" "${PROJECT_NAME}-cluster-role"; then
        success "âœ… Cluster role existe: ${PROJECT_NAME}-cluster-role"
    else
        error "âŒ Cluster role nÃ£o encontrado"
        all_good=false
    fi

    if resource_exists "iam-role" "${PROJECT_NAME}-node-role"; then
        success "âœ… Node role existe: ${PROJECT_NAME}-node-role"
    else
        error "âŒ Node role nÃ£o encontrado"
        all_good=false
    fi

    # 6. Verificar infraestrutura de rede
    info "6. Verificando infraestrutura de rede..."
    if resource_exists "vpc" "${PROJECT_NAME}-vpc"; then
        success "âœ… VPC existe: ${PROJECT_NAME}-vpc"
    else
        error "âŒ VPC nÃ£o encontrada"
        all_good=false
    fi

    echo ""
    if [ "$all_good" = true ]; then
        success "ğŸ‰ VERIFICAÃ‡ÃƒO CONCLUÃDA: Todos os componentes estÃ£o funcionando!"
        
        # Mostrar informaÃ§Ãµes de custos
        echo ""
        info "ğŸ’° CUSTOS ESTIMADOS (MENSAIS):"
        info "   EKS Cluster: ~$72.00/mÃªs"
        info "   EC2 Nodes (${NODE_DESIRED_SIZE}x $INSTANCE_TYPE): ~$15.00/mÃªs"
        info "   VPC/Networking: ~$2.00/mÃªs"
        info "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        info "   TOTAL ESTIMADO: ~$89.00/mÃªs"
        
        # Mostrar credenciais GitHub se existirem
        if [ -f .eks-github-credentials ]; then
            echo ""
            info "ğŸ”‘ CREDENCIAIS GITHUB ACTIONS:"
            source .eks-github-credentials
            info "   AWS_ACCESS_KEY_ID: $GITHUB_ACCESS_KEY"
            info "   AWS_SECRET_ACCESS_KEY: [HIDDEN]"
            info "   AWS_REGION: $AWS_REGION"
            info "   EKS_CLUSTER_NAME: $CLUSTER_NAME"
        fi
        
        return 0
    else
        error "âŒ VERIFICAÃ‡ÃƒO FALHOU: Alguns componentes nÃ£o estÃ£o funcionando corretamente"
        return 1
    fi
}

# ============================================================================
# FUNÃ‡ÃƒO PARA GERAR RELATÃ“RIO FINAL
# ============================================================================

generate_final_report() {
    step_header "ğŸ“„ GERANDO RELATÃ“RIO FINAL"
    
    local account_id=$(aws sts get-caller-identity --query Account --output text)
    
    # Carregar informaÃ§Ãµes se existirem
    local vpc_id="N/A"
    local subnet1_id="N/A"
    local subnet2_id="N/A"
    local sg_id="N/A"
    local github_access_key="N/A"
    
    if [ -f .eks-network-info ]; then
        source .eks-network-info
        vpc_id=$VPC_ID
        subnet1_id=$SUBNET1_ID
        subnet2_id=$SUBNET2_ID
        sg_id=$SG_ID
    fi
    
    if [ -f .eks-github-credentials ]; then
        source .eks-github-credentials
        github_access_key=$GITHUB_ACCESS_KEY
    fi

    cat > eks-deployment-report.txt << EOF
ğŸ‰ EKS DEPLOYMENT REPORT - $(date)

============================================================================
ğŸ“‹ INFORMAÃ‡Ã•ES DO CLUSTER
============================================================================
   Nome do Cluster: $CLUSTER_NAME
   RegiÃ£o AWS: $AWS_REGION
   VersÃ£o Kubernetes: 1.30
   Account ID: $account_id
   Tipo de InstÃ¢ncia: $INSTANCE_TYPE
   Nodes Desejados: $NODE_DESIRED_SIZE

============================================================================
ğŸ—ï¸ INFRAESTRUTURA CRIADA
============================================================================
   VPC ID: $vpc_id
   Subnet 1: $subnet1_id (${AWS_REGION}a)
   Subnet 2: $subnet2_id (${AWS_REGION}b)
   Security Group: $sg_id

============================================================================
ğŸ‘¥ USUÃRIOS E ROLES CRIADOS
============================================================================
   ğŸ”§ Admin User: ${PROJECT_NAME}-admin
   ğŸ¤– GitHub CI/CD User: ${PROJECT_NAME}-github-cicd
   ğŸ‘¤ Cluster Role: ${PROJECT_NAME}-cluster-role
   ğŸ–¥ï¸ Node Role: ${PROJECT_NAME}-node-role

============================================================================
ğŸ”‘ CREDENCIAIS PARA GITHUB ACTIONS
============================================================================
   AWS_ACCESS_KEY_ID: $github_access_key
   AWS_SECRET_ACCESS_KEY: [Consulte arquivo .eks-github-credentials]
   AWS_REGION: $AWS_REGION
   EKS_CLUSTER_NAME: $CLUSTER_NAME

   ğŸ“ CONFIGURAR NO GITHUB:
   1. Settings > Secrets and variables > Actions
   2. Adicionar as secrets acima
   3. Usar nos workflows

============================================================================
ğŸ’° CUSTOS ESTIMADOS (MENSAIS)
============================================================================
   ğŸ’¸ EKS Cluster: ~$72.00/mÃªs
   ğŸ’¸ EC2 Nodes (${NODE_DESIRED_SIZE}x $INSTANCE_TYPE): ~$15.00/mÃªs
   ğŸ’¸ VPC/Networking: ~$2.00/mÃªs
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ğŸ’° TOTAL ESTIMADO: ~$89.00/mÃªs

============================================================================
ğŸ” COMANDOS DE VERIFICAÃ‡ÃƒO
============================================================================
   # Verificar nodes
   kubectl get nodes
   
   # Verificar pods do sistema
   kubectl get pods -A
   
   # InformaÃ§Ãµes do cluster
   kubectl cluster-info
   
   # Status do cluster
   aws eks describe-cluster --name $CLUSTER_NAME --region $AWS_REGION

============================================================================
ğŸš€ PRÃ“XIMOS PASSOS
============================================================================
   1. ğŸ”‘ Configurar GitHub Actions com as credenciais
   2. ğŸ“¦ Criar repositÃ³rio ECR para imagens Docker
   3. ğŸš€ Desenvolver aplicaÃ§Ãµes para Kubernetes
   4. ğŸ“Š Configurar monitoramento (CloudWatch)
   5. ğŸ”’ Revisar polÃ­ticas de seguranÃ§a

============================================================================
ğŸ“ COMANDOS ÃšTEIS
============================================================================
   # Verificar deployment completo
   $0 --verify
   
   # Executar passo especÃ­fico
   $0 --step [1-7]
   
   # Verificar prÃ©-requisitos
   $0 --check

============================================================================
âš ï¸ IMPORTANTE
============================================================================
   â€¢ Recursos geram custos 24/7 (~$89/mÃªs)
   â€¢ Mantenha credenciais seguras
   â€¢ Monitore custos regularmente
   â€¢ Use tags para organizaÃ§Ã£o

RelatÃ³rio gerado em: $(date)
EOF

    success "âœ… RelatÃ³rio salvo em: eks-deployment-report.txt"
    
    if [ -f .eks-github-credentials ]; then
        info "ğŸ”‘ Credenciais GitHub salvas em: .eks-github-credentials"
    fi
    
    if [ -f .eks-network-info ]; then
        info "ğŸ—ï¸ InformaÃ§Ãµes de rede salvas em: .eks-network-info"
    fi
}

# ============================================================================
# FUNÃ‡ÃƒO PRINCIPAL DE CONTROLE
# ============================================================================

show_help() {
    echo -e "${CYAN}"
    echo "============================================================================"
    echo "ğŸš€ EKS DEPLOYMENT SCRIPT v3.0 - MODULAR E SEGURO"
    echo "============================================================================"
    echo -e "${NC}"
    echo ""
    echo "USO:"
    echo "  $0 --all              # Executar todos os passos (1-7)"
    echo "  $0 --step N           # Executar passo especÃ­fico (1-7)"
    echo "  $0 --verify           # Verificar deployment completo"
    echo "  $0 --check            # Verificar prÃ©-requisitos"
    echo "  $0 --report           # Gerar relatÃ³rio final"
    echo "  $0 --help             # Mostrar esta ajuda"
    echo ""
    echo "PASSOS DISPONÃVEIS:"
    echo "  1. Criar infraestrutura de rede (VPC, Subnets, etc.)"
    echo "  2. Criar IAM Roles para EKS"
    echo "  3. Criar usuÃ¡rio admin"
    echo "  4. Criar usuÃ¡rio GitHub CI/CD"
    echo "  5. Aguardar propagaÃ§Ã£o dos roles"
    echo "  6. Criar cluster EKS"
    echo "  7. Criar node group e configurar kubectl"
    echo ""
    echo "EXEMPLOS:"
    echo "  chmod +x $0"
    echo "  ./$0 --check          # Verificar prÃ©-requisitos primeiro"
    echo "  ./$0 --all            # Criar tudo"
    echo "  ./$0 --step 1         # Apenas criar rede"
    echo "  ./$0 --verify         # Verificar se estÃ¡ funcionando"
    echo ""
    echo "CONFIGURAÃ‡Ã•ES ATUAIS:"
    echo "  Projeto: $PROJECT_NAME"
    echo "  Cluster: $CLUSTER_NAME"
    echo "  RegiÃ£o: $AWS_REGION"
    echo "  InstÃ¢ncia: $INSTANCE_TYPE"
    echo "  Nodes: $NODE_DESIRED_SIZE"
    echo ""
}

# Controle principal
case "${1:-}" in
    --all)
        check_prerequisites
        step1_create_network
        step2_create_eks_roles
        step3_create_admin_user
        step4_create_github_user
        step5_wait_propagation
        step6_create_eks_cluster
        step7_create_node_group
        generate_final_report
        echo ""
        success "ğŸ‰ DEPLOYMENT COMPLETO! Veja eks-deployment-report.txt para detalhes."
        ;;
    --step)
        if [ -z "$2" ]; then
            error "Especifique o nÃºmero do passo (1-7)"
        fi
        
        case "$2" in
            1) check_prerequisites && step1_create_network ;;
            2) check_prerequisites && step2_create_eks_roles ;;
            3) check_prerequisites && step3_create_admin_user ;;
            4) check_prerequisites && step4_create_github_user ;;
            5) step5_wait_propagation ;;
            6) check_prerequisites && step6_create_eks_cluster ;;
            7) check_prerequisites && step7_create_node_group ;;
            *) error "Passo invÃ¡lido. Use 1-7." ;;
        esac
        ;;
    --verify)
        verify_deployment
        ;;
    --check)
        check_prerequisites
        ;;
    --report)
        generate_final_report
        ;;
    --help|-h)
        show_help
        ;;
    "")
        show_help
        ;;
    *)
        error "ParÃ¢metro invÃ¡lido: $1. Use --help para ver opÃ§Ãµes disponÃ­veis."
        ;;
esac
